{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9e15290",
   "metadata": {},
   "source": [
    "# Yelp Fusion API\n",
    "\n",
    "With millions of business updates every month, Yelp Fusion delivers the most current and most accurate local data available. Choose from dozens of attributes per business, and as millions of new reviews and photos are added by active Yelp users, the Yelp data set remains unparalleled in its rich detail, freshness, and accuracy.\n",
    "\n",
    "For our project, we will be pulling restaurant data for New York City based on the zip codes. These zip codes correspond to the housing price data downloaded from [Redfin](https://www.redfin.com/news/data-center/) and [Zillow](https://www.zillow.com/research/data/). \n",
    "\n",
    "We narrowed down the cities that had a minimum of 10 zip codes for our analysis. \n",
    "The following code for API was repeated 10 times to pull a total of 6014 zip codes\n",
    "\n",
    "**Data Source** : [Yelp Fusion API](https://www.yelp.com/developers/v3/manage_app)\n",
    "Note: This needs an authorized API key from Yelp Fusion. \n",
    "\n",
    "##### Yelp Fusion API limitations\n",
    "Yelp API data limits - Yelp allows you to pull only 1,000 results at a time and only 50 per request with 5000 API pulls approved every 24 hours. \n",
    "\n",
    "##### Method\n",
    "We created a list of zip codes for each borough from the housing price dataset. To get around the Yelp API limitation of 1,000 results at a time and only 50 per request, we adapted a function written by \"rspiro9 on Yelp vs Inspection Analysis for NYC\". We pulled 150 restaurants per zip code. \n",
    "\n",
    "\n",
    "### N This notebook was run 10  times  to pull a total of 6014 zip codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d079cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2b7c7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = 'QLEWkFuExPpizCGBhUEJ1d7cN9nCUvbDLqPGhW1G39uQBk7ybMEhtkPjjOkwHAwjLZZbiMnjXCNRpuqTeve9Vr49gmC-zlJeSoq066tvRd2WxvgDhBO0Q1WWkLFBYnYx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1225c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the yelp business search API: https://www.yelp.com/developers/documentation/v3/business_search\n",
    "\n",
    "# headers contain the api key.\n",
    "headers = {'Authorization': 'Bearer {}'.format(api_key)}\n",
    "url = 'https://api.yelp.com/v3/businesses/search'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "86f7b52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## List of zip codes per NYC borough. Change this list for every borough. \n",
    "neighborhoods = [\"zip codes go here\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f2b8858",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create temporary dataframe to hold data:\n",
    "nyc = [[] for i in range(len(neighborhoods))] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319f3d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to draw in data for each zipcode:\n",
    "for x in range(len(neighborhoods)):\n",
    "    print('---------------------------------------------')\n",
    "    print('Gathering Data for {}'.format(neighborhoods[x]))\n",
    "    print('---------------------------------------------')\n",
    "    \n",
    "    for y in range(5):\n",
    "        location = neighborhoods[x]\n",
    "        term = \"Restaurants\"\n",
    "        search_limit = 50\n",
    "        offset = 50 * y\n",
    "        categories = \"(restaurants, All)\"\n",
    "        sort_by = 'distance'\n",
    "        url_params = {\n",
    "                     'location': location.replace(' ', '+'),\n",
    "                     'term' : term,\n",
    "                      'limit': search_limit,\n",
    "                     'offset': offset,\n",
    "                     'categories': categories,\n",
    "                     'sorty_by': sort_by\n",
    "                     }\n",
    "        \n",
    "        response = requests.get(url, headers=headers, params=url_params)\n",
    "        print('***** {} Restaurants #{} - #{} ....{}'.format(neighborhoods[x], \n",
    "                                                             offset+1, offset+search_limit,\n",
    "                                                             response))\n",
    "        nyc[x].append(response)\n",
    "\n",
    "print(response)\n",
    "print(type(response.text))\n",
    "print(response.json().keys())\n",
    "print(response.text[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9953e0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for any empty business lists:\n",
    "for x in range(len(neighborhoods)):\n",
    "    try: \n",
    "        for y in range(20):\n",
    "            num = len(nyc[x][y].json()['businesses'])\n",
    "            if num != 50:\n",
    "                print(neighborhoods[x], y, num)\n",
    "    except:\n",
    "        print(\"Invalid data. Skipping entry...\")\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d53a708",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the compiled data into dataframe and remove any empty data:\n",
    "df = pd.DataFrame()\n",
    "for x in range(len(neighborhoods)):\n",
    "    try:\n",
    "        for y in range(20):\n",
    "            df_temp = pd.DataFrame.from_dict(nyc[x][y].json()['businesses'])\n",
    "            if not df_temp.empty:\n",
    "                df_temp.loc[:,'neighborhood'] = neighborhoods[x]\n",
    "                df = df.append(df_temp)\n",
    "    except:\n",
    "        print(\"Invalid data. Skipping entry...\")\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "84cfe0b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(58966, 17)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b759d73",
   "metadata": {},
   "source": [
    "#### Saving file as pickle\n",
    "* The pickle module keeps track of the objects it has already serialized, so that later references to the same object wonâ€™t be serialized again, thus allowing for faster execution time.\n",
    "* Allows saving model in very little time.\n",
    "* Good For small models with fewer parameters like the one we used.\n",
    "\n",
    "Save each pull as a separate pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a67dc943",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Dataset: (data pulled 3/28/22)\n",
    "with open ('Yelp_API/data_pull_six.pickle','wb')as f:\n",
    "    pickle.dump(df, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34336c63",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "mlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
